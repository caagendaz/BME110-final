"""
NLP Handler for BioQuery
Converts natural language requests to EMBOSS tool calls using Google Gemini or Ollama
"""

import json
from typing import Dict, Optional, Tuple
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import requests
import re
import os


class NLPHandler:
    """Convert natural language queries to EMBOSS tool commands using Google Gemini or Ollama"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-2.5-flash", mode: str = "cloud"):
        """Initialize the NLP handler with Google Gemini or Ollama
        
        Args:
            api_key: Google API key (only for cloud mode)
            model: Model name to use
            mode: 'cloud' for Gemini or 'local' for Ollama
        """
        self.mode = mode
        self.model_name = model
        
        if mode == 'cloud':
            # Cloud mode - use Google Gemini
            self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
            if not self.api_key:
                raise ValueError("Google API key required for cloud mode. Set GOOGLE_API_KEY environment variable or pass api_key parameter.")
            
            # Configure Gemini with the stable v1 API
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(f"models/{model}")
            self.ollama_url = None
        else:
            # Local mode - use Ollama
            self.api_key = None
            self.model = None
            self.ollama_url = "http://localhost:11434"
            self.model_name = "llama3.2:latest"  # Default Ollama model
        
        # Build system prompt based on mode
        self.system_prompt = self._build_system_prompt()
    
    def _build_system_prompt(self) -> str:
        """Build system prompt based on mode (cloud vs local)"""
        
        base_prompt = """You are a bioinformatics assistant that helps users run EMBOSS analysis tools"""
        
        if self.mode == 'cloud':
            base_prompt += """ and query genomic databases."""
        else:
            base_prompt += "."
        
        base_prompt += """

When a user asks a question about DNA/protein sequences"""
        
        if self.mode == 'cloud':
            base_prompt += """, genomic regions, genes, or tools"""
        
        base_prompt += """, respond with a JSON object containing:

FOR SINGLE OPERATIONS:
1. "tool": the tool name"""
        
        if self.mode == 'cloud':
            base_prompt += """ (EMBOSS tool, 'genome_query', or 'gene_query')"""
        else:
            base_prompt += """ (EMBOSS tool only)"""
        
        base_prompt += """
2. "parameters": a dict with required parameters
3. "explanation": a brief explanation of what will be done

FOR MULTI-STEP OPERATIONS (when user says "then", "and then", "after that", "next", etc.):
1. "steps": a list of step objects, each containing "tool" and "parameters"
2. "explanation": overall explanation of the workflow
3. "use_previous_result": whether step N+1 should use output from step N

EMBOSS tools (use 'sequence' for raw DNA/protein sequences):
- translate: Translate DNA to protein. Needs "sequence"
- reverse: Reverse complement DNA. Needs "sequence"
- orf: Find open reading frames. Needs "sequence" and optional "min_size"
- align: Align two sequences. Needs "seq1" and "seq2"
- pattern: Search for patterns. Needs "sequence" and optional "pattern"
- restriction: Find restriction sites. Needs "sequence" and optional "enzyme"
- shuffle: Shuffle sequence. Needs "sequence"
- info: Get sequence info. Needs "sequence"
- sixframe: Show all 6 reading frames. Needs "sequence"
- gc: Calculate GC content. Needs "sequence"
- pepstats: Calculate protein statistics (molecular weight, amino acid composition, charge, etc.). Needs "sequence" (protein). USE THIS for "molecular weight", "MW", "mass"
- iep: Calculate isoelectric point (pI) of a protein. Needs "sequence" (protein). USE THIS for "isoelectric point", "pI"
- cusp: Calculate codon usage statistics. Needs "sequence" (DNA). USE THIS for "codon usage"
"""
        
        if self.mode == 'cloud':
            base_prompt += """
CLOUD-ONLY FEATURES:
- blast: Search NCBI databases for similar sequences. Needs "sequence" and optional "blast_type", "database", "max_results", "exclude_taxa", "word_size", "organism"
- blastn: DNA BLAST search. Needs "sequence" and optional "exclude_taxa" (e.g., "primates"), "word_size", "organism" (e.g., "Archaea", "Bacteria")
- blastp: Protein BLAST search. Needs "sequence" and optional "exclude_taxa", "word_size", "organism"
- blastx: DNA to protein BLAST search (translates query). Needs "sequence" (DNA) and searches protein database
- tblastn: Protein to DNA BLAST search (translates database). Needs "sequence" (protein) and searches nucleotide database
- blat: UCSC BLAT search. Needs "sequence" and optional "database"
- genome_query: Query UCSC Genome Browser. Needs "genome", "chrom", "start", "end"
- gene_query: Look up gene information. Needs "gene_name" and optional "genome" (default hg38), optional "sequence_type" (mRNA, protein, or both)
- gtex: Get tissue expression data. Needs "gene_name" and optional "top_n"
- ucsc_gene: Get gene position from UCSC. Needs "gene_name"
- ucsc_table_query: Query UCSC Table Browser. Needs "genome", "track", optional "chrom", "start", "end", "filter_field", "filter_value"
- pubmed_search: Search PubMed literature. Needs "query" and optional "year", "max_results"
- track_intersection: Find overlaps between two genome tracks. Needs "genome", "track1", "track2", optional "chrom", "max_results"
- find_neighboring_genes: Find genes adjacent to a target gene. Needs "gene_name", optional "genome" (default hg38), optional "track" (default knownGene)
- bedtools: Find overlapping genomic regions. Needs "file_a" and "file_b"

IMPORTANT TRACK INTERSECTION:
- If user asks for "overlap", "intersect", "features in common" between tracks: use track_intersection
- Common track names: "tRNAs", "knownGene", "GENCODE V48" (maps to knownGene)
- Example: "tRNAs that overlap with GENCODE" ‚Üí track_intersection with track1="tRNAs", track2="GENCODE V48"

IMPORTANT NEIGHBORING GENES:
- If user asks for "genes near", "neighboring genes", "flanking genes", "genes to the left and right": use find_neighboring_genes
- Needs only gene_name (e.g., "CARS1"), automatically finds genes on both sides with distances
- Example: "genes neighboring CARS1" ‚Üí find_neighboring_genes with gene_name="CARS1", genome="hg38"

IMPORTANT BLAST PARAMETERS:
- "word_size": Word size for BLAST sensitivity (e.g., 11, 7, 3). Smaller = more sensitive but slower
- "organism": Limit to taxonomic group (e.g., "Archaea", "Bacteria", "Mammalia")
- "exclude_taxa": Exclude specific taxa (e.g., "primates")
- If user says "Archaea domain", "limit to Archaea", "in Archaea": use "organism": "Archaea"
- If user says "Bacteria domain", "limit to Bacteria", "in Bacteria": use "organism": "Bacteria"
- If user says "wordsize of 11", "word size 7": use "word_size": 11 or 7

IMPORTANT BLAST FILTERING:
- If user says "exclude primates", "non-primate", "excluding primates": add parameter "exclude_taxa": "primates"
- If user says "mammals only" or "mammalian species": no filtering needed (BLAST already searches all organisms)

MULTI-STEP WORKFLOWS (gene_query ‚Üí BLAST):
- If user asks to get gene info THEN BLAST the sequence:
  Step 1: gene_query with gene_name and sequence_type (specify "mRNA" if user wants mRNA, "protein" if user wants protein)
  Step 2: blastn (for mRNA) or blastp (for protein) with "sequence": "USE_PREVIOUS_RESULT"
- The system will automatically fetch the correct sequence type from the gene

COMPLEX GENOMICS ANALYSIS WORKFLOWS:
- For comprehensive sequence characterization, CHAIN multiple tools in steps:
  Example: "Characterize this mystery sequence [ATGC...] using hg19"
  Step 1: blat with sequence=[ATGC...], genome=hg19 ‚Üí get genomic location
  Step 2: ucsc_table with location from Step 1, track="ncbiRefSeq" ‚Üí check gene overlaps
  Step 3: find_neighboring_genes (if gene found in Step 2) ‚Üí get flanking genes
  Step 4: blast with sequence, database="refseq_rna" ‚Üí search RNA databases
  
- For conservation/chromHMM/ChIP-seq: provide UCSC Browser links, these require manual visualization
  Format: "View at https://genome.ucsc.edu/cgi-bin/hgTracks?db={genome}&position={chr}:{start}-{end}"

- For sequence ‚Üí genomic analysis workflow:
  1. Use blat to map sequence to genome location (chr:start-end)
  2. Use ucsc_table to query tracks at that location (genes, conservation, etc.)
  3. Use gene_query if specific gene is identified
  4. Use blast for database similarity searches
  
- Available UCSC tracks: ncbiRefSeq, knownGene, tRNAs, cons100way, wgEncodeBroadHmmGm12878HMM
- For conservation/chromHMM/ChIP-seq not in REST API: provide UCSC Browser link instructions

GENE SYMBOL SUPPORT (cloud only):
- If user mentions a GENE NAME/SYMBOL (like TP53, BRCA1, ALKBH1): use gene_name parameter with appropriate tool
- For gene structure questions: use gene_query
- To apply tools to genes: use tool with gene_name parameter
"""
        
        base_prompt += """
Decision logic:
- IMPORTANT PROTEIN ANALYSIS: If "molecular weight", "mass", "MW" -> use pepstats (NOT info)
- If "isoelectric point", "pI", "charge" -> use iep (NOT info)
- If "codon usage", "codon frequency" -> use cusp
- If raw DNA/RNA/protein sequences (ATGCCC, MKLA...) -> use appropriate EMBOSS tool with sequence parameter
- IMPORTANT: If user provides ONLY a DNA sequence without specifying an operation (especially long sequences >100bp), AND asks general questions like "what is this", "analyze", "characterize", or provides NO specific instruction -> assume they want genomic characterization with multi-step: blat + ucsc_table + blast
"""
        
        if self.mode == 'cloud':
            base_prompt += """- If GENE NAME/SYMBOL mentioned -> use gene_query or tool with gene_name parameter
- If chromosome/genomic position -> use genome_query
- If "BLAST", "search", "similar", "homologous" -> use blast/blastn/blastp
- If "characterize", "analyze", "mystery sequence", "what is this sequence", "identify sequence" -> create multi-step workflow:
  Step 1: blat to map to genome
  Step 2: ucsc_table to check gene overlaps
  Step 3: blast against refseq_rna for database matches
"""
        
        base_prompt += """- Otherwise use appropriate EMBOSS tool

Examples:
- "Translate ATGCCC" -> translate tool with sequence: ATGCCC
- "Calculate GC content of ATGCATGC" -> gc tool with sequence: ATGCATGC
- "What's the reverse complement of ATGC?" -> reverse tool with sequence: ATGC
- "Calculate molecular weight of MKTAYIAK" -> pepstats tool with sequence: MKTAYIAK
- "Isoelectric point of MKTAYIAK?" -> iep tool with sequence: MKTAYIAK
"""
        
        if self.mode == 'cloud':
            base_prompt += """- "Find gene info for TP53" -> gene_query with gene_name: TP53
- "Translate BRCA1" -> translate tool with gene_name: BRCA1
- "BLAST this sequence: ATGCGATCG" -> blast tool with sequence: ATGCGATCG
- "Characterize this sequence [ATGC...]" or "What is this sequence?" -> multi-step:
  {"steps": [
    {"tool": "blat", "parameters": {"sequence": "[ATGC...]", "database": "hg19"}},
    {"tool": "ucsc_table", "parameters": {"genome": "hg19", "track": "ncbiRefSeq", "chrom": "USE_RESULT", "start": "USE_RESULT", "end": "USE_RESULT"}},
    {"tool": "blast", "parameters": {"sequence": "[ATGC...]", "blast_type": "blastn", "database": "refseq_rna", "max_results": 5}}
  ], "explanation": "Map sequence to genome, check gene overlaps, and search RNA databases"}
"""
        
        return base_prompt
    
    def _build_legacy_system_prompt(self) -> str:
        """Original full system prompt for cloud mode (kept for reference)"""
        
        return """You are a bioinformatics assistant that helps users run EMBOSS analysis tools and query genomic databases.

When a user asks a question about DNA/protein sequences, genomic regions, genes, or tools, respond with a JSON object containing:

FOR SINGLE OPERATIONS:
1. "tool": the tool name (EMBOSS tool, 'genome_query', or 'gene_query')
2. "parameters": a dict with required parameters
3. "explanation": a brief explanation of what will be done

FOR MULTI-STEP OPERATIONS (when user says "then", "and then", "after that", "next", etc.):
1. "steps": a list of step objects, each containing "tool" and "parameters"
2. "explanation": overall explanation of the workflow
3. "use_previous_result": whether step N+1 should use output from step N

IMPORTANT MULTI-STEP CHAINING RULES:
- If Step 1 is gene_query and Step 2 is BLAST: DO NOT include "sequence" parameter in Step 2. The system will automatically fetch the sequence from the gene.
- If Step 1 is gene_query and Step 2 is translate/gc/analysis: DO NOT include "sequence" parameter in Step 2. The system will use the gene's sequence.
- Only provide "sequence" parameter if user explicitly gives you a raw sequence.
- For gene_name chaining: Just pass the gene_name in Step 1, and the gene_name (not sequence) in dependent steps - the system will resolve it.

IMPORTANT: When a user mentions a GENE SYMBOL (like ALKBH1, TP53, BRCA1), use the gene_name parameter, NOT sequence.

EMBOSS tools (use 'gene_name' for gene symbols, 'sequence' for raw DNA/protein sequences):
- translate: Translate DNA to protein (NOT to RNA - see dna_to_rna below). Needs "gene_name" OR "sequence", optional "frame" (1-3) and "transcript_variant" (e.g., "transcript variant 5")
- dna_to_rna: Convert DNA to RNA (T ‚Üí U). Needs "gene_name" OR "sequence". Use when user says "convert to RNA", "make RNA", "transcribe", "DNA to RNA", "translate to RNA", "translate into RNA"
- rna_to_dna: Convert RNA to DNA (U ‚Üí T). Needs "sequence". Use when user says "convert to DNA", "RNA to DNA"
- reverse: Reverse complement DNA. Needs "gene_name" OR "sequence"
- orf: Find open reading frames. Needs "gene_name" OR "sequence" and optional "min_size"
- align: Align two sequences. Needs "seq1" and "seq2"
- pattern: Search for patterns. Needs "gene_name" OR "sequence" and optional "pattern"
- restriction: Find restriction sites. Needs "gene_name" OR "sequence" and optional "enzyme"
- shuffle: Shuffle sequence. Needs "gene_name" OR "sequence"
- info: Get sequence info. Needs "gene_name" OR "sequence"
- sixframe: Show all 6 reading frames. Needs "gene_name" OR "sequence"
- gc: Calculate GC content. Needs "gene_name" OR "sequence"
- blast: Search NCBI databases for similar sequences. Needs "sequence" and optional "blast_type" (blastn/blastp/blastx), "database" (nt/nr), "max_results" (default 10), "expect_threshold" (default 10.0)
- blastn: DNA BLAST search. Needs "sequence"
- blastp: Protein BLAST search. Needs "sequence"
- blastx: DNA to protein BLAST search. Needs "sequence"
- search: General sequence search (uses blastn by default). Needs "sequence"
- pepstats: Calculate protein statistics (molecular weight, amino acid composition, charge, etc.). Needs "sequence" (protein sequence). USE THIS for "molecular weight", "MW", "mass", "protein stats", "amino acid composition"
- iep: Calculate isoelectric point (pI) of a protein. Needs "sequence" (protein sequence). USE THIS for "isoelectric point", "pI", "charge at pH"
- cusp: Calculate codon usage statistics. Needs "gene_name" OR "sequence" (DNA). USE THIS for "codon usage", "codon frequency", "codon bias"
- wordcount: Count word frequencies in sequences. Needs "sequence" and optional "word_size"
- bedtools: Find overlapping genomic regions. Needs "file_a" and "file_b" (BED format data or file paths)
- blat: UCSC BLAT search for near-exact genome matches. Needs "sequence" and optional "database" (default hg38)
- ucsc_gene: Get gene position info from UCSC. Needs "gene_name" and optional "database" (default hg38)
- gtex: Get tissue expression data from GTEx. Needs "gene_name" and optional "top_n" (default 10)

GENOME QUERY tool:
- genome_query: Query UCSC Genome Browser for genomic regions. Needs "genome", "chrom", "start", "end"

GENE QUERY tool:
- gene_query: Look up gene information (exons, CDS, transcript length). Needs "gene_name" and optional "genome" (default hg38) and "track" (default gencode)

Decision logic:
- IMPORTANT: If user says "translate to/into RNA" or "translate ... RNA" -> use dna_to_rna (NOT translate tool)
- If user says "translate" alone or "translate to protein" -> use translate tool
- IMPORTANT PROTEIN ANALYSIS: If user asks for "molecular weight", "mass", "MW", "protein statistics", "amino acid composition" -> use pepstats (NOT info)
- If user asks for "isoelectric point", "pI", "charge" -> use iep (NOT info)
- If user asks for "codon usage", "codon frequency", "codon bias" -> use cusp
- If user mentions a GENE NAME/SYMBOL (like ALKBH1, TP53, BRCA1, etc.):
  - If asking about gene structure (exons, CDS, transcripts) -> use gene_query with gene_name
  - If asking to apply a tool (translate, gc, BLAST, etc.) to that gene -> use the tool with gene_name parameter and transcript_variant if specified
- If user provides raw DNA/RNA/protein sequences (like ATGCCC or MKLA...) or mentions "BLAST", "search", "similar sequences", "homologous" -> use the appropriate search/BLAST tool with sequence parameter
- If user mentions chromosome/genomic position -> use genome_query
- Otherwise use appropriate EMBOSS tool

MULTI-STEP EXAMPLE:
User: "Find gene info for ALKBH1, then calculate its GC content"
Response:
{
  "steps": [
    {"tool": "gene_query", "parameters": {"gene_name": "ALKBH1"}},
    {"tool": "gc", "parameters": {"gene_name": "ALKBH1"}}
  ],
  "explanation": "First query gene information for ALKBH1, then calculate GC content of its sequence",
  "use_previous_result": false
}

TRANSCRIPT VARIANT EXTRACTION:
- If user mentions "transcript variant N" or "primary variant" or "variant N", extract this as "transcript_variant": "transcript variant N"
- Examples: "transcript variant 5" -> "transcript_variant": "transcript variant 5"

Examples:
- "How many exons in ALKBH1?" -> gene_query with gene_name: ALKBH1
- "Find the gc content of ALKBH1" -> gc tool with gene_name: ALKBH1
- "Translate ATGCCC" -> translate tool with sequence: ATGCCC
- "Translate TP53" -> translate tool with gene_name: TP53
- "What's the reverse complement of BRCA1?" -> reverse tool with gene_name: BRCA1
- "Give the length of the protein made from transcript variant 5 of CARS1" -> translate tool with gene_name: CARS1, transcript_variant: "transcript variant 5"
- "Find gene info for ALKBH1, then calculate its GC content" -> multi-step with gene_query followed by gc
- "BLAST this sequence against the human genome: ATGCGATCG" -> blast tool with sequence: ATGCGATCG, blast_type: blastn
- "Find BRCA1 sequence, then BLAST it to find homologous genes" -> multi-step: gene_query for BRCA1 (NO sequence param in step 2), then blast (NO sequence param - system auto-fetches)
- "Search for similar proteins to MKLASELKD" -> blastp tool with sequence: MKLASELKD
- "Find homologous DNA sequences to this: ATGCCC" -> blastn tool with sequence: ATGCCC
- "Find TP53 gene info then translate it" -> multi-step: gene_query(gene_name: TP53), translate(gene_name: TP53, NOT sequence)
- "Calculate the molecular weight of MKTAYIAK" -> pepstats tool with sequence: MKTAYIAK
- "What is the isoelectric point of MKTAYIAK?" -> iep tool with sequence: MKTAYIAK
- "Show protein statistics for MKTAYIAK" -> pepstats tool with sequence: MKTAYIAK
- "What is the codon usage for TP53?" -> cusp tool with gene_name: TP53
- "Which tissue has highest expression of SOCS3?" -> gtex tool with gene_name: SOCS3

Always respond with ONLY valid JSON, no other text. Start with { and end with }"""

    def _split_numbered_questions(self, query: str) -> list:
        """Split a query into numbered questions if present
        
        Detects patterns like:
        1. Question one
        2. Question two
        
        or
        
        Question 1: Text
        Question 2: Text
        
        Args:
            query: Full query text
        
        Returns:
            List of individual questions (empty list if no numbering detected)
        """
        import re
        
        # Pattern 1: "1.", "2.", etc. at start of lines
        pattern1 = r'^\s*\d+[\.)]\s+'
        
        # Pattern 2: "Question 1:", "Q1:", etc.
        pattern2 = r'^\s*[Qq](?:uestion)?\s*\d+\s*:\s*'
        
        lines = query.split('\n')
        questions = []
        current_question = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Check if this line starts a new question
            if re.match(pattern1, line) or re.match(pattern2, line):
                # Save previous question if exists
                if current_question:
                    questions.append(' '.join(current_question))
                # Start new question (remove number prefix)
                clean_line = re.sub(pattern1, '', line)
                clean_line = re.sub(pattern2, '', clean_line)
                current_question = [clean_line]
            else:
                # Continue current question
                current_question.append(line)
        
        # Add last question
        if current_question:
            questions.append(' '.join(current_question))
        
        # Only return questions if we found multiple
        return questions if len(questions) > 1 else []

    def _parse_multiple_questions(self, questions: list) -> Tuple[bool, Dict]:
        """Parse multiple unrelated questions independently
        
        Args:
            questions: List of question strings
        
        Returns:
            Tuple of (success: bool, result dict with 'questions' list)
        """
        results = []
        
        for i, question in enumerate(questions, 1):
            try:
                # Parse each question independently
                full_prompt = f"{self.system_prompt}\n\nUser query: {question}\n\nRespond with JSON only:"
                
                # Call appropriate LLM based on mode
                if self.mode == 'cloud':
                    response_text = self._call_gemini(full_prompt)
                else:
                    response_text = self._call_ollama(full_prompt)
                
                parsed = json.loads(response_text)
                
                # Clean up multi-step parameters if needed
                if 'steps' in parsed:
                    parsed['steps'] = self._cleanup_multistep_parameters(parsed['steps'])
                
                results.append({
                    'question_number': i,
                    'question_text': question,
                    'parsed': parsed,
                    'success': True
                })
                
            except Exception as e:
                results.append({
                    'question_number': i,
                    'question_text': question,
                    'error': str(e),
                    'success': False
                })
        
        return True, {
            'type': 'multiple_questions',
            'questions': results,
            'total': len(questions)
        }

    def parse_user_query(self, query: str) -> Tuple[bool, Dict]:
        """Parse a user query and extract tool information
        
        Supports:
        - Single queries: "Translate SOCS3"
        - Multi-step queries: "Find SOCS3 then translate it"
        - Multiple unrelated questions: "1. What is SOCS3? 2. Translate ALKBH1"
        
        Args:
            query: User's natural language query
        
        Returns:
            Tuple of (success: bool, result: dict with tool, parameters, explanation OR steps, explanation OR questions list)
        """
        try:
            # Check if this is a multi-question query (numbered questions)
            questions = self._split_numbered_questions(query)
            
            if len(questions) > 1:
                # Handle multiple unrelated questions
                return self._parse_multiple_questions(questions)
            
            # Single query or multi-step workflow - process normally
            # Sanitize query for Gemini to avoid content filters
            sanitized_query = self._sanitize_query_for_gemini(query) if self.mode == 'cloud' else query
            
            # Create the full prompt with system instructions
            full_prompt = f"{self.system_prompt}\n\nUser query: {sanitized_query}\n\nRespond with JSON only:"
            
            # Call appropriate LLM based on mode
            if self.mode == 'cloud':
                try:
                    response_text = self._call_gemini(full_prompt)
                except Exception as gemini_error:
                    # Check if this was a safety filter block
                    error_msg = str(gemini_error)
                    if "safety filter" in error_msg.lower() or "blocked" in error_msg.lower():
                        print(f"‚ö†Ô∏è Gemini safety filter triggered. Automatically falling back to Ollama...")
                        print(f"   (Cloud features remain active)")
                        # Fallback to Ollama while keeping cloud mode active
                        response_text = self._call_ollama_fallback(full_prompt)
                    else:
                        # Not a safety filter issue, re-raise
                        raise
            else:
                response_text = self._call_ollama(full_prompt)
            
            # Parse JSON response
            try:
                result = json.loads(response_text)
            except json.JSONDecodeError as e:
                # If JSON parsing fails, log the problematic response for debugging
                print(f"DEBUG - Failed to parse JSON. Raw response:\n{response_text}\n")
                raise
            
            # Validate the response - can be either single tool or multi-step
            if 'steps' in result:
                # Multi-step query - clean up parameters
                if not isinstance(result['steps'], list) or len(result['steps']) == 0:
                    return False, {"error": "Invalid steps format"}
                
                # Smart parameter cleanup for multi-step workflows
                result['steps'] = self._cleanup_multistep_parameters(result['steps'])
                return True, result
            elif 'tool' in result and 'parameters' in result:
                # Single-step query
                return True, result
            else:
                return False, {"error": "Invalid response format from LLM"}
        
        except json.JSONDecodeError as e:
            return False, {"error": f"Failed to parse LLM response as JSON: {str(e)}"}
        except Exception as e:
            return False, {"error": f"Error processing query: {str(e)}"}
    
    def _cleanup_multistep_parameters(self, steps: list) -> list:
        """Clean up parameters in multi-step queries to enable proper chaining
        
        Args:
            steps: List of step dictionaries
        
        Returns:
            Cleaned steps with proper parameter handling
        """
        cleaned_steps = []
        
        for i, step in enumerate(steps):
            cleaned_step = step.copy()
            params = step.get('parameters', {})
            
            # If this is step 2+ and has "use previous result" markers, clean them
            if i > 0 and params:
                # Replace placeholder values that indicate chaining
                for key, value in params.items():
                    if isinstance(value, str):
                        # Common placeholders for "use previous result"
                        if value.lower() in ['previous', 'from_previous', 'result', 'output', 
                                             'previous_result', 'from previous step', 'use previous']:
                            params[key] = 'USE_PREVIOUS_RESULT'
            
            cleaned_steps.append(cleaned_step)
        
        return cleaned_steps
    
    def _sanitize_query_for_gemini(self, query: str) -> str:
        """Sanitize query to avoid triggering Gemini's content filters
        
        This wraps the user query in a formal bioinformatics context that signals
        to Gemini this is legitimate scientific work, rather than doing word-by-word
        replacements which are hard to maintain.
        
        Args:
            query: Original user query
        
        Returns:
            Sanitized query wrapped in scientific context
        """
        # Strip out potentially triggering conversational language
        # Convert to purely technical format
        
        # Remove questions marks that make it seem conversational
        technical_query = query.replace("?", ".")
        
        # Wrap in extremely formal technical specification format
        sanitized = f"""GENOMIC DATA EXTRACTION SPECIFICATION

Protocol: Bioinformatics database query protocol per NCBI/UCSC Genome Browser API standards
Classification: Educational genomics research - BME110 course assignment
Data Sources: UCSC Genome Browser (hg38), GENCODE V48 gene annotation track, NCBI taxonomy database

Technical Parameters:
{technical_query}

Required Output Format: JSON object containing tool identifier and parameter dictionary for computational genomics pipeline execution.

Analysis Type: Gene annotation retrieval, genomic coordinate mapping, sequence homology search via BLAST nucleotide algorithm, taxonomic classification."""
        
        return sanitized
    
    def _legacy_cleanup_multistep_parameters(self, steps: list) -> list:
        """Legacy cleanup for multi-step parameters (kept for reference)
        
        Rules:
        - If previous step is gene_query and current step is BLAST/translate/gc, remove 'sequence' param
        - This allows the system to automatically fetch sequences and chain them
        
        Args:
            steps: List of step dicts
        
        Returns:
            List of cleaned step dicts
        """
        cleaned_steps = []
        
        for idx, step in enumerate(steps):
            step_copy = step.copy()
            tool_name = step_copy.get('tool', '').lower()
            parameters = step_copy.get('parameters', {})
            if not isinstance(parameters, dict):
                parameters = {}
            parameters = parameters.copy()  # Make a copy to avoid modifying original
            
            # Check if previous step was gene_query
            if idx > 0:
                prev_step = steps[idx - 1]
                prev_tool = prev_step.get('tool', '').lower()
                
                print(f"üîç Step {idx}: tool='{tool_name}', prev_tool='{prev_tool}'")
                
                # If previous was gene_query and current is a dependent tool
                # Including 'blast' and variations
                dependent_tools = ['blast', 'blastn', 'blastp', 'blastx', 'search', 'translate', 'gc', 'gc_content', 'reverse', 'orf', 'getorf']
                
                if prev_tool == 'gene_query' and tool_name in dependent_tools:
                    print(f"  ‚úì Previous is gene_query, current is {tool_name}")
                    # Remove 'sequence' if it's just a gene name (not actual bases)
                    if 'sequence' in parameters:
                        seq_value = parameters['sequence']
                        print(f"  Found sequence param: '{seq_value}'")
                        # If sequence is short and looks like a gene name (not pure DNA/protein sequence)
                        # Gene names: ALKBH1, TP53, BRCA1 (letters/numbers, short)
                        # DNA sequences: ATCGATCGATCG (only ATCGN)
                        is_short = len(seq_value) < 20
                        is_mostly_letters = sum(1 for c in seq_value if c.isalpha()) > len(seq_value) * 0.5
                        is_not_pure_sequence = not all(c.upper() in 'ATCGNU' for c in seq_value if c.isalpha())
                        
                        if isinstance(seq_value, str) and is_short and (is_mostly_letters or is_not_pure_sequence):
                            print(f"  üîß REMOVING sequence='{seq_value}' (detected as gene name)")
                            del parameters['sequence']
                        else:
                            print(f"  Not removing: short={is_short}, mostly_letters={is_mostly_letters}, not_pure_seq={is_not_pure_sequence}")
                    else:
                        print(f"  No 'sequence' param found")
            
            step_copy['parameters'] = parameters
            cleaned_steps.append(step_copy)
        
        return cleaned_steps
    
    def suggest_tools(self, query: str) -> list:
        """Suggest relevant EMBOSS tools based on a query
        
        Args:
            query: User's question
        
        Returns:
            List of suggested tool names
        """
        query_lower = query.lower()
        suggestions = []
        
        # Simple keyword matching for suggestions
        if any(word in query_lower for word in ['translate', 'protein', 'amino']):
            suggestions.append('translate')
        
        if any(word in query_lower for word in ['reverse', 'complement', 'rc']):
            suggestions.append('reverse')
        
        if any(word in query_lower for word in ['orf', 'open reading frame', 'gene', 'start codon']):
            suggestions.append('orf')
        
        if any(word in query_lower for word in ['align', 'alignment', 'compare', 'similarity']):
            suggestions.append('align')
        
        if any(word in query_lower for word in ['restrict', 'restriction', 'enzyme', 'cut']):
            suggestions.append('restriction')
        
        if any(word in query_lower for word in ['info', 'information', 'length', 'gc content']):
            suggestions.append('info')
        
        if any(word in query_lower for word in ['pattern', 'motif', 'search', 'find']):
            suggestions.append('pattern')
        
        if any(word in query_lower for word in ['six frame', 'sixframe', 'all frames']):
            suggestions.append('sixframe')
        
        if any(word in query_lower for word in ['shuffle', 'randomize']):
            suggestions.append('shuffle')
        
        return suggestions
    
    def validate_sequence(self, sequence: str) -> Tuple[bool, str]:
        """Validate if a sequence is in correct format
        
        Args:
            sequence: DNA or protein sequence
        
        Returns:
            Tuple of (is_valid: bool, message: str)
        """
        # Remove whitespace and convert to uppercase
        seq_clean = sequence.replace('\n', '').replace(' ', '').replace('\t', '').upper()
        
        if not seq_clean:
            return False, "Sequence is empty"
        
        # Check for valid DNA characters
        valid_dna = set('ATCGN')
        valid_protein = set('ACDEFGHIKLMNPQRSTVWY')
        
        seq_set = set(seq_clean)
        
        # Check if it looks like DNA or protein
        if seq_set.issubset(valid_dna):
            return True, f"Valid DNA sequence ({len(seq_clean)} bp)"
        elif seq_set.issubset(valid_protein):
            return True, f"Valid protein sequence ({len(seq_clean)} aa)"
        else:
            invalid_chars = seq_set - (valid_dna | valid_protein)
            return False, f"Invalid characters in sequence: {invalid_chars}"
    
    def extract_sequence_from_query(self, query: str) -> Optional[str]:
        """Try to extract a sequence from a user query
        
        Args:
            query: User query that might contain a sequence
        
        Returns:
            Extracted sequence or None
        """
        # Look for FASTA format
        fasta_match = re.search(r'>.*?\n([ATCGN]+)', query, re.IGNORECASE)
        if fasta_match:
            return fasta_match.group(1)
        
        # Look for plain sequence (continuous letters)
        seq_match = re.search(r'\b([ATCGN]{15,})\b', query, re.IGNORECASE)
        if seq_match:
            return seq_match.group(1)
        
        return None
    
    def format_response(self, success: bool, tool_info: Dict, result: str = None) -> str:
        """Format a nicely readable response
        
        Args:
            success: Whether the operation was successful
            tool_info: Information about the tool used
            result: The result from running the tool
        
        Returns:
            Formatted response string
        """
        if not success:
            return f"‚ùå Error: {tool_info.get('error', 'Unknown error')}"
        
        response = f"‚úì Running {tool_info.get('tool', 'tool')}\n"
        response += f"üìã Explanation: {tool_info.get('explanation', 'N/A')}\n"
        
        if tool_info.get('parameters'):
            response += f"‚öôÔ∏è  Parameters:\n"
            for param, value in tool_info['parameters'].items():
                if isinstance(value, str) and len(value) > 50:
                    response += f"   - {param}: {value[:50]}...\n"
                else:
                    response += f"   - {param}: {value}\n"
        
        if result:
            response += f"\nüìä Results:\n{result}"
        
        return response
    
    def test_connection(self) -> bool:
        """Test if LLM connection is working
        
        Returns:
            bool: True if connection successful
        """
        try:
            if self.mode == 'cloud':
                # Test Gemini connection
                response = self.model.generate_content("Test")
                if response:
                    print(f"‚úì Connected to Google Gemini")
                    print(f"‚úì Model: {self.model_name}")
                    return True
                else:
                    print("‚úó No response from Gemini")
                    return False
            else:
                # Test Ollama connection
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
                response.raise_for_status()
                models = response.json().get('models', [])
                print(f"‚úì Connected to Ollama")
                print(f"‚úì Model: {self.model_name}")
                print(f"‚úì Available models: {len(models)}")
                return True
        except Exception as e:
            if self.mode == 'cloud':
                print(f"‚úó Failed to connect to Gemini: {str(e)}")
            else:
                print(f"‚úó Failed to connect to Ollama: {str(e)}")
                print("  Make sure Ollama is running with: ollama serve")
            return False
    
    def _call_gemini(self, prompt: str) -> str:
        """Call Google Gemini API
        
        Args:
            prompt: Full prompt with system instructions
        
        Returns:
            Cleaned response text
        """
        response = self.model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=1024,
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )
        
        # Check if response was blocked
        if not response.candidates or len(response.candidates) == 0:
            raise Exception(f"‚ö†Ô∏è Google's safety filters blocked this query. This is a false positive on legitimate scientific work.\n\nüí° SOLUTION: Switch to 'Local (Ollama)' mode in the sidebar - it has no content restrictions and works perfectly for bioinformatics queries.\n\nTechnical details: {response.prompt_feedback}")
        
        candidate = response.candidates[0]
        if candidate.finish_reason == 2:  # SAFETY
            raise Exception(f"‚ö†Ô∏è Google's safety filters blocked this query. This is a false positive on legitimate scientific work.\n\nüí° SOLUTION: Switch to 'Local (Ollama)' mode in the sidebar - it has no content restrictions and works perfectly for bioinformatics queries.")
        
        if not candidate.content or not candidate.content.parts:
            raise Exception(f"No content in response. Finish reason: {candidate.finish_reason}")
        
        response_text = response.text.strip()
        
        # Remove markdown code blocks if present
        if response_text.startswith('```'):
            response_text = response_text.split('```')[1]
            if response_text.startswith('json'):
                response_text = response_text[4:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        
        response_text = response_text.strip()
        
        # Additional cleanup for common JSON issues
        response_text = response_text.replace('\\"', '"')
        response_text = re.sub(r',(\s*[}\]])', r'\1', response_text)
        
        return response_text
    
    def _call_ollama_fallback(self, prompt: str) -> str:
        """Fallback to Ollama when Gemini is blocked, but keep using cloud system prompt
        
        This allows us to use Ollama's unrestricted parsing while maintaining
        access to all cloud features (BLAST, gene queries, etc.)
        
        Args:
            prompt: Full prompt with system instructions (cloud version)
        
        Returns:
            Cleaned response text
        """
        ollama_url = "http://localhost:11434"
        model_name = "llama3.2:latest"
        
        try:
            response = requests.post(
                f"{ollama_url}/api/generate",
                json={
                    "model": model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 1024,
                    }
                },
                timeout=120  # Increased timeout for complex queries
            )
            response.raise_for_status()
            
            response_json = response.json()
            response_text = response_json.get('response', '')
            
            # Clean up markdown code blocks
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            
            response_text = response_text.strip()
            response_text = response_text.replace('\\"', '"')
            response_text = re.sub(r',(\s*[}\]])', r'\1', response_text)
            
            return response_text
            
        except requests.exceptions.ConnectionError:
            raise Exception(
                "‚ö†Ô∏è Gemini blocked, but Ollama fallback unavailable.\n\n"
                "To enable automatic fallback:\n"
                "1. Install Ollama: https://ollama.ai\n"
                "2. Run: ollama serve\n"
                "3. Pull model: ollama pull llama3.2\n\n"
                "Or switch to Local mode in the sidebar."
            )
        except requests.exceptions.Timeout:
            raise Exception(
                "‚ö†Ô∏è Ollama query timed out (>120s).\n\n"
                "This query may be too complex for the local model.\n"
                "Try:\n"
                "1. Simplify your query\n"
                "2. Use the Genome Browser tab directly (Tab 3)\n"
                "3. Break into smaller queries"
            )
        except Exception as e:
            raise Exception(f"Ollama fallback failed: {str(e)}")
    
    def _call_ollama(self, prompt: str) -> str:
        """Call Ollama API
        
        Args:
            prompt: Full prompt with system instructions
        
        Returns:
            Cleaned response text
        """
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "format": "json",
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 1024
                    }
                },
                timeout=120
            )
            
            response.raise_for_status()
            result = response.json()
            response_text = result.get('response', '').strip()
            
            # Clean markdown if present
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            
            return response_text.strip()
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Failed to connect to Ollama: {str(e)}. Make sure Ollama is running with: ollama serve")


# Example usage
if __name__ == "__main__":
    print("=== BioQuery NLP Handler ===\n")
    
    # Initialize handler
    handler = NLPHandler(mode='local')
    
    # Test connection
    print("Testing LLM connection...")
    if handler.test_connection():
        print("\n" + "="*50 + "\n")
        
        # Test queries
        test_queries = [
            "Translate this DNA sequence to protein: ATGAAATTTCCCGGGAAATTT",
            "What is the reverse complement of ATGAAATTT?",
            "Find all open reading frames in ATGAAATTTCCCGGGAAATTTAAAGGG",
        ]
        
        for query in test_queries:
            print(f"Query: {query}")
            success, result = handler.parse_user_query(query)
            if success:
                print(f"‚úì Tool: {result.get('tool')}")
                print(f"‚úì Parameters: {result.get('parameters')}")
                print(f"‚úì Explanation: {result.get('explanation')}")
            else:
                print(f"‚úó Error: {result.get('error')}")
            print()
    else:
        print("Cannot proceed without Ollama connection")
